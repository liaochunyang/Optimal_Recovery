{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducible for the paper\n",
    "\n",
    "# Radius of Information for Two Intersected Centered Hyperellipsoids and Implications in Optimal Recovery from Inaccurate Data\n",
    "\n",
    "by S.Foucart and C.Liao\n",
    "\n",
    "This reproducible was written by S. Foucart and C. Liao in December 2023.\n",
    "\n",
    "CVXPY [2] is required to execute this reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERSECTION OF 2 HYPERELLIPSOIDS\n",
    "\n",
    "### Setting the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of the ambiant Hilbert space H\n",
    "N = 20;\n",
    "# two Hilbert-valued linear maps defined on H\n",
    "R = np.random.randn(N,N)\n",
    "S = np.random.randn(N,N)\n",
    "# dimension of another Hilbert space Z which is the range of quantity of interest\n",
    "n = 10\n",
    "# quantity of interest \n",
    "Q = np.random.randn(n,N)\n",
    "# number of observations\n",
    "m = 7\n",
    "# observation map\n",
    "Lam = np.random.randn(m,N)\n",
    "# construct a basis for ker(Lam)\n",
    "U_aux,__ = np.linalg.qr(Lam.T, mode='complete')\n",
    "# the columns of U are an ONB for ker(Lam)\n",
    "U = U_aux[:,m:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the radius of information (Theorem 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the two-hyperellipsoid-intersection model set,\n",
      "the radius of information of the observation map for the estimation of Q is 1.937.\n"
     ]
    }
   ],
   "source": [
    "a = cp.Variable((1,1), nonneg=True)\n",
    "b = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(a+b)\n",
    "constraints = [U.T@(cp.multiply(a,R.T@R)+cp.multiply(b,S.T@S)-Q.T@Q)@U>>0]\n",
    "# The symmetric matrices R', S' and Q'defined in Eq.(11) of the paper are computed here as \n",
    "# U'*R'*R*U, U'*S'*S*U, and U'*Q'*Q*U, respectively.\n",
    "sdp1 = cp.Problem(objective,constraints)\n",
    "sdp1.solve()\n",
    "a = a.value[0,0]\n",
    "b = b.value[0,0]\n",
    "rad = np.sqrt(a+b)\n",
    "print('For the two-hyperellipsoid-intersection model set,\\n'\n",
    "    'the radius of information of the observation map '\n",
    "    f'for the estimation of Q is {rad:0.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification of the side result (Proposition 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999999999999998, 1.0000421582731926]\n",
      "\n",
      "[1.9369968870370655, 1.9369539348605072]\n"
     ]
    }
   ],
   "source": [
    "# map T_N defined in the proof\n",
    "TN = U.T@(a*R.T@R+b*S.T@S)@U\n",
    "TN_aux = np.linalg.inv(sp.linalg.sqrtm(TN))\n",
    "__,v = np.linalg.eigh(TN_aux@U.T@Q.T@Q@U@TN_aux)\n",
    "h_aux = U@TN_aux@v[:,-1]\n",
    "h = h_aux/np.linalg.norm(R@h_aux);\n",
    "# the norm of Rh and Sh should both be =1\n",
    "print([np.linalg.norm(R@h), np.linalg.norm(S@h)])\n",
    "print('')\n",
    "# the norm of Qh should equal the radius of information\n",
    "print([np.linalg.norm(Q@h), rad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERSECTION OF 3 HYPERELLIPSOIDS\n",
    "\n",
    "following the remark after Proposition 6 at the end of Subsection 2.3\n",
    "\n",
    "### The norms $\\|R_i h_\\#\\|$ can all be equal to 1 in some situations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0000022599097735, 0.9999999972536573]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix the random seed to guarantee equality of these norms\n",
    "np.random.seed(1)    # comment out this line to test different instances\n",
    "# dimension of the ambiant Hilbert space H\n",
    "N = 20\n",
    "# three Hilbert-valued linear maps defined on H\n",
    "R1 = np.random.randn(N,N)\n",
    "R2 = np.random.randn(N,N)\n",
    "R3 = np.random.randn(N,N)\n",
    "# dimension of another Hilbert space Z which is the range of quantity of interest\n",
    "n = 10\n",
    "# quantity of interest \n",
    "Q = np.random.randn(n,N)\n",
    "# number of observations\n",
    "m = 7\n",
    "# observation map\n",
    "Lam = np.random.randn(m,N)\n",
    "# construct a basis for ker(Lam)\n",
    "U_aux,__ = np.linalg.qr(Lam.T, mode='complete')\n",
    "# the columns of U are an ONB for ker(Lam)\n",
    "U = U_aux[:,m:]\n",
    "\n",
    "# solve an SDP\n",
    "a1 = cp.Variable((1,1), nonneg=True)\n",
    "a2 = cp.Variable((1,1), nonneg=True)\n",
    "a3 = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(a1+a2+a3)\n",
    "constraints = [U.T@(cp.multiply(a1,R1.T@R1)+cp.multiply(a2,R2.T@R2) + cp.multiply(a3,R3.T@R3) - Q.T@Q)@U>>0]\n",
    "\n",
    "sdp2 = cp.Problem(objective,constraints)\n",
    "sdp2.solve()\n",
    "a1 = a1.value[0,0]\n",
    "a2 = a2.value[0,0]\n",
    "a3 = a3.value[0,0]\n",
    "\n",
    "\n",
    "# inspired by the side results, we compute norms of R1*h, R2*h, R3*h\n",
    "TN = U.T@(a1*R1.T@R1+a2*R2.T@R2+a3*R3.T@R3)@U\n",
    "TN_aux = np.linalg.inv(sp.linalg.sqrtm(TN))\n",
    "__,v = np.linalg.eigh(TN_aux@U.T@Q.T@Q@U@TN_aux)\n",
    "h_aux = U@TN_aux@v[:,-1]\n",
    "h = h_aux/np.linalg.norm(R1@h_aux);\n",
    "[np.linalg.norm(R1@h), np.linalg.norm(R2@h), np.linalg.norm(R3@h)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the norms of $R_1h_\\#$, $R_2h_\\#$, and $R_3h_\\#$ are all equal to 1 in this case, a linear constrained regularization map is optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... but the norms $\\|R_ih_\\#\\|$ are not always equal, in particular when the  $R_i$'s are orthogonal projectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999999999999999, 1.7057597192030172, 2.4623431808309166]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension of the ambiant Hilbert space H\n",
    "N = 20\n",
    "# three orthogonal projectors\n",
    "n1 = 3\n",
    "V1 = np.random.randn(N,n1)\n",
    "R1 = np.identity(N) - V1@np.linalg.inv(V1.T@V1)@V1.T\n",
    "n2 = 5\n",
    "V2 = np.random.randn(N,n2)\n",
    "R2 = np.identity(N) - V2@np.linalg.inv(V2.T@V2)@V2.T\n",
    "n3 = 12\n",
    "V3 = np.random.randn(N,n3)\n",
    "R1 = np.identity(N) - V3@np.linalg.inv(V3.T@V3)@V3.T\n",
    "# dimension of another Hilbert space Z which is the range of quantity of interest\n",
    "n = 10;\n",
    "# quantity of interest \n",
    "Q = np.random.randn(n,N);\n",
    "# number of observations\n",
    "m = 7;\n",
    "# observation map\n",
    "Lam = np.random.randn(m,N);\n",
    "# construct a basis for ker(Lam)\n",
    "U_aux,__ = np.linalg.qr(Lam.T, mode='complete');\n",
    "# the columns of U are an ONB for ker(Lam)\n",
    "U = U_aux[:,m:]; \n",
    "\n",
    "# solve an SDP\n",
    "a1 = cp.Variable((1,1), nonneg=True)\n",
    "a2 = cp.Variable((1,1), nonneg=True)\n",
    "a3 = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(a1+a2+a3)\n",
    "constraints = [U.T@(cp.multiply(a1,R1.T@R1)+cp.multiply(a2,R2.T@R2) + cp.multiply(a3,R3.T@R3) - Q.T@Q)@U>>0]\n",
    "\n",
    "sdp2 = cp.Problem(objective,constraints)\n",
    "sdp2.solve()\n",
    "a1 = a1.value[0,0]\n",
    "a2 = a2.value[0,0]\n",
    "a3 = a3.value[0,0]\n",
    "\n",
    "\n",
    "# inspired by the side results...\n",
    "TN = U.T@(a1*R1.T@R1+a2*R2.T@R2+a3*R3.T@R3)@U\n",
    "TN_aux = np.linalg.inv(sp.linalg.sqrtm(TN))\n",
    "__,v = np.linalg.eigh(TN_aux@U.T@Q.T@Q@U@TN_aux)\n",
    "h_aux = U@TN_aux@v[:,-1]\n",
    "h = h_aux/np.linalg.norm(R1@h_aux);\n",
    "# usually, the norms of R1*h, R2*h, and R3*h are not equal\n",
    "[np.linalg.norm(R1@h), np.linalg.norm(R2@h), np.linalg.norm(R3@h)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-space problem\n",
    "\n",
    "following section 3.1\n",
    "\n",
    "### Setting of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of the ambiant Hilbert space H\n",
    "N = 20;\n",
    "# two orthogonal projectors defined on H\n",
    "n1 = 5\n",
    "V = np.random.randn(N,n1)\n",
    "PV = np.identity(N) - V@np.linalg.inv(V.T@V)@V.T\n",
    "n2 = 3\n",
    "W = np.random.randn(N,n2)\n",
    "PW = np.identity(N) - W@np.linalg.inv(W.T@W)@W.T\n",
    "# approximability parameters\n",
    "eps = 0.2; \n",
    "eta = 0.8; \n",
    "# dimension of another Hilbert space Z which is the range of quantity of interest\n",
    "n = 10\n",
    "# quantity of interest \n",
    "Q = np.random.randn(n,N)\n",
    "# number of observations\n",
    "m = 7\n",
    "# observation map\n",
    "Lam = np.random.randn(m,N)\n",
    "# construct a basis for ker(Lam)\n",
    "U_aux,__ = np.linalg.qr(Lam.T, mode='complete')\n",
    "# the columns of U are an ONB for ker(Lam)\n",
    "U = U_aux[:,m:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the radius of information (Theorem 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the two-space model set,\n",
      "the radius of information of the observation map for the estimation of Q is 2.390.\n"
     ]
    }
   ],
   "source": [
    "c = cp.Variable((1,1), nonneg=True)\n",
    "d = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(c*eps**2+d*eta**2)\n",
    "constraints = [U.T@(cp.multiply(c,PV)+cp.multiply(d,PW)-Q.T@Q)@U>>0]\n",
    "sdp1 = cp.Problem(objective,constraints)\n",
    "sdp1.solve()\n",
    "c = c.value[0,0]\n",
    "d = d.value[0,0]\n",
    "rad = np.sqrt(c*eps**2+d*eta**2)\n",
    "print('For the two-space model set,\\n'\n",
    "    'the radius of information of the observation map '\n",
    "    f'for the estimation of Q is {rad:0.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-INACCURATE DATA\n",
    "\n",
    "following Section 3.2\n",
    "\n",
    "Numerical experiments were done in the reproducible files accompanying [3] for $Q=\\mathrm{Id}$ and $S=\\mathrm{Id}$ and accompanying [4] for an arbitrary $Q$ but still with $S=\\mathrm{Id}$. We refer readers to the following links:\n",
    "\n",
    "Reproducible file for [3]: https://htmlpreview.github.io/?https://github.com/foucart/COR/blob/master/MATLAB/web/ORHilbert_Reg_repro.html\n",
    "\n",
    "Reproducible file for [4]: https://github.com/liaochunyang/ORofGraphSignals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIXED ACCURATE AND L2-INACCURATE DATA \n",
    "\n",
    "following Section 3.3\n",
    "\n",
    "### setting of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of the ambiant Hilbert space H\n",
    "N = 20;\n",
    "# Hilbert-valued liner map defined on H\n",
    "R = np.random.randn(N,N)\n",
    "# dimension of another Hilbert space Z which is the range of quantity of interest\n",
    "n = 10\n",
    "# quantity of interest \n",
    "Q = np.random.randn(n,N)\n",
    "# number of observations\n",
    "m = 7\n",
    "# observation map\n",
    "Lam = np.random.randn(m,N)\n",
    "# two Hilbert-valued linear maps defined on R^m\n",
    "S1 = np.random.randn(m,m);                       # represents S' in the paper\n",
    "S2 = np.random.randn(m,m);                       # represents S'' in the paper\n",
    "# approximability parameter\n",
    "eps = 0.5;\n",
    "# uncertainty parameter\n",
    "eta = 0.3; \n",
    "# construct a basis for ker(S1*Lam)\n",
    "U_aux,__ = np.linalg.qr( (S1@Lam).T, mode='complete')\n",
    "# the columns of U are an ONB for ker(Lam)\n",
    "U = U_aux[:,m:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the radius of information (Theorem 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the the mixed accurate and inaccurate model,\n",
      "the radius of information of the observation map for the estimation of Q is 1.909.\n"
     ]
    }
   ],
   "source": [
    "c = cp.Variable((1,1), nonneg=True)\n",
    "d = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(c*eps**2+d*eta**2)\n",
    "constraints = [U.T@(cp.multiply(c,R.T@R)+cp.multiply(d,Lam.T@S2.T@S2@Lam)-Q.T@Q)@U>>0]\n",
    "sdp1 = cp.Problem(objective,constraints)\n",
    "sdp1.solve()\n",
    "c = c.value[0,0]\n",
    "d = d.value[0,0]\n",
    "rad = np.sqrt(c*eps**2+d*eta**2)\n",
    "print('For the the mixed accurate and inaccurate model,\\n'\n",
    "    'the radius of information of the observation map '\n",
    "    f'for the estimation of Q is {rad:0.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-INACCURATE DATA\n",
    "\n",
    "following Section 4\n",
    "\n",
    "### Case 1: Small $\\eta$\n",
    "\n",
    "#### Setting the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension of the ambiant Hilbert space H\n",
    "N = 20;\n",
    "# Hilbert-valued linear map defined on H\n",
    "R = np.random.randn(N,N)\n",
    "# approximability parameter\n",
    "eps = 0.5\n",
    "# dimension of another Hilbert space Z which is the range of quantity of interest\n",
    "n = 10\n",
    "# quantity of interest \n",
    "Q = np.random.randn(n,N)\n",
    "# number of observations\n",
    "m = 7\n",
    "# observation map\n",
    "Lam = np.random.randn(m,N)\n",
    "# pseudo-inverse of Lam\n",
    "Lamdag = Lam.T@np.linalg.inv(Lam@Lam.T)\n",
    "# uncertainty parameter\n",
    "eta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparations for the calculations to come\n",
    "\n",
    "We introduce linear maps defined on the extended Hilbert space $H\\times\\mathbb{R}$ as in Eq.(38) of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented observation map Gam\n",
    "Gam = np.column_stack((Lam, np.zeros([m,1])))\n",
    "# construct a basis for ker(Gam)\n",
    "U_aux,__ = np.linalg.qr(Gam.T, mode='complete')\n",
    "# the columns of U are an ONB for ker(Lam)\n",
    "U = U_aux[:,m:]\n",
    "# augmented Hilbert-valued linear map S\n",
    "S = np.zeros([1,N+1])\n",
    "S[:,-1] = 1/eta\n",
    "# augmented Hilbert-valued linear maps R^i and Q^i\n",
    "R_aug = np.zeros((N,N+1,m))\n",
    "Q_aug = np.zeros((n,N+1,m))\n",
    "for i in range(m):\n",
    "    ui = Lamdag[:,i]\n",
    "    # the i-th element in the tensors R_aug and Q_aug represent R^i and Q^i, respectively\n",
    "    R_aug[:,:,i] = 1/eps*np.column_stack((R,-R@ui))\n",
    "    Q_aug[:,:,i] = np.column_stack((Q,-Q@ui))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the lower bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_p = np.zeros((m,1))\n",
    "# array to store the extremizers a and b\n",
    "ab = np.zeros((m,2))\n",
    "for i in range(m):\n",
    "    Ri = R_aug[:,:,i]\n",
    "    Qi = Q_aug[:,:,i]\n",
    "    a = cp.Variable((1,1), nonneg=True)\n",
    "    b = cp.Variable((1,1), nonneg=True)\n",
    "    objective = cp.Minimize(a+b)\n",
    "    constraints = [U.T@(cp.multiply(a,Ri.T@Ri)+cp.multiply(b,S.T@S)-Qi.T@Qi)@U>>0]\n",
    "    sdp1 = cp.Problem(objective,constraints)\n",
    "    sdp1.solve()\n",
    "    a = a.value[0,0]\n",
    "    b = b.value[0,0]\n",
    "    lb_p[i] = np.sqrt(a+b)\n",
    "    ab[i,0], ab[i,1] = a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction of the regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamdag = Gam.T@np.linalg.inv(Gam@Gam.T)\n",
    "Del = np.zeros((n,m,m))\n",
    "for j in range(m):\n",
    "    aj = ab[j,0]\n",
    "    bj = ab[j,1]\n",
    "    Rj = R_aug[:,:,j]\n",
    "    Qj = Q_aug[:,:,j]\n",
    "    aux = Gamdag - U@np.linalg.inv(U.T@(aj*Rj.T@Rj+bj*S.T@S)@U)@U.T@(aj*Rj.T@Rj+bj*S.T@S)@Gamdag\n",
    "    Del[:,:,j] = Qj@aux   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification of the sufficient condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.205473102819632, 1.2054730967856953]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.argmax(lb_p)\n",
    "Mk = np.zeros((m,1))\n",
    "for i in range(m):\n",
    "    Ri = R_aug[:,:,i]\n",
    "    Qi = Q_aug[:,:,i]\n",
    "    aux = Qi - Del[:,:,i]@Gam\n",
    "    a = cp.Variable((1,1), nonneg=True)\n",
    "    b = cp.Variable((1,1), nonneg=True)\n",
    "    objective = cp.Minimize(a+b)\n",
    "    constraints = [cp.multiply(a,Ri.T@Ri) + cp.multiply(b,S.T@S) - aux.T@aux>>0]\n",
    "    sdp1 = cp.Problem(objective,constraints)\n",
    "    sdp1.solve()\n",
    "    a = a.value[0,0]\n",
    "    b = b.value[0,0]\n",
    "    Mk[i] = np.sqrt(a+b)\n",
    "    \n",
    "# sufficient condition: the maximum of Mk should be equal to lb_p(k)\n",
    "[ np.max(Mk), lb_p[k,0] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification of the side results (proposition 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.205473102819632, 1.2054730967856953, 1.2054731202339832]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = cp.Variable((m,1), nonneg=True)\n",
    "b = cp.Variable((m,1), nonneg=True)\n",
    "Del_lin = cp.Variable((n,m))        # a linear recovery map treated as a variable in the SDP\n",
    "gam = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(gam)\n",
    "constraints = [a[i]+b[i]<=gam for i in range(m)]\n",
    "for i in range(m):\n",
    "    aux = Q_aug[:,:,i] - Del_lin@Gam\n",
    "    Ri = R_aug[:,:,i]\n",
    "    Mi1 = cp.hstack( (np.identity(n), aux) ) \n",
    "    Mi2 = cp.hstack( (aux.T, cp.multiply(a[i],Ri.T@Ri) + cp.multiply(b[i],S.T@S)) )\n",
    "    constraints += [cp.vstack((Mi1,Mi2))>>0]\n",
    "sdp1 = cp.Problem(objective,constraints)\n",
    "sdp1.solve()\n",
    "gam = gam.value[0,0]\n",
    "\n",
    "# the optimal value of this SDP should coincide with the maxima of Mk and lb_p(k),\n",
    "# confirming that there is a a linear recovery map with minimal global worst-case error\n",
    "# when eta is small enough\n",
    "[np.max(Mk), lb_p[k,0], np.sqrt(gam)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The norm of difference between linear map obtained by regularization \n",
      "and the linear map obtained as solution of SDP is 0.119,\n",
      "illustrating once again the nonuniqueness of optimal recovery maps.\n"
     ]
    }
   ],
   "source": [
    "Del_lin = Del_lin.value[:,:]\n",
    "print('The norm of difference between linear map obtained by regularization \\n'\n",
    "    f'and the linear map obtained as solution of SDP is {np.linalg.norm(Del[:,:,k]-Del_lin):.3f},\\n' \n",
    "      'illustrating once again the nonuniqueness of optimal recovery maps.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Large $\\eta$\n",
    "\n",
    "We repeat case 1 and select a large $\\eta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the problem \n",
    "\n",
    "# dimension of the ambiant Hilbert space H\n",
    "N = 20;\n",
    "# Hilbert-valued linear map defined on H\n",
    "R = np.random.randn(N,N)\n",
    "# approximability parameter\n",
    "eps = 0.5\n",
    "# dimension of another Hilbert space Z which is the range of quantity of interest\n",
    "n = 10\n",
    "# quantity of interest \n",
    "Q = np.random.randn(n,N)\n",
    "# number of observations\n",
    "m = 7\n",
    "# observation map\n",
    "Lam = np.random.randn(m,N)\n",
    "# pseudo-inverse of Lam\n",
    "Lamdag = Lam.T@np.linalg.inv(Lam@Lam.T)\n",
    "# uncertainty parameter\n",
    "eta = 5\n",
    "\n",
    "\n",
    "\n",
    "## Preparations for the calculations to come\n",
    "\n",
    "# augmented observation map Gam\n",
    "Gam = np.column_stack((Lam, np.zeros([m,1])))\n",
    "# construct a basis for ker(Gam)\n",
    "U_aux,__ = np.linalg.qr(Gam.T, mode='complete')\n",
    "# the columns of U are an ONB for ker(Lam)\n",
    "U = U_aux[:,m:]\n",
    "# augmented Hilbert-valued linear map S\n",
    "S = np.zeros([1,N+1])\n",
    "S[:,-1] = 1/eta\n",
    "# augmented Hilbert-valued linear maps R^i and Q^i\n",
    "R_aug = np.zeros((N,N+1,m))\n",
    "Q_aug = np.zeros((n,N+1,m))\n",
    "for i in range(m):\n",
    "    ui = Lamdag[:,i]\n",
    "    # the i-th elements in the tensors R_aug and Q_aug represent R^i and Q^i, respectively\n",
    "    R_aug[:,:,i] = 1/eps*np.column_stack((R,-R@ui))\n",
    "    Q_aug[:,:,i] = np.column_stack((Q,-Q@ui))\n",
    "\n",
    "    \n",
    "    \n",
    "## Compute the lower bounds\n",
    "\n",
    "lb_p = np.zeros((m,1))\n",
    "# array to store the extremizers a and b\n",
    "ab = np.zeros((m,2))\n",
    "for i in range(m):\n",
    "    Ri = R_aug[:,:,i]\n",
    "    Qi = Q_aug[:,:,i]\n",
    "    a = cp.Variable((1,1), nonneg=True)\n",
    "    b = cp.Variable((1,1), nonneg=True)\n",
    "    objective = cp.Minimize(a+b)\n",
    "    constraints = [U.T@(cp.multiply(a,Ri.T@Ri)+cp.multiply(b,S.T@S)-Qi.T@Qi)@U>>0]\n",
    "    sdp1 = cp.Problem(objective,constraints)\n",
    "    sdp1.solve()\n",
    "    a = a.value[0,0]\n",
    "    b = b.value[0,0]\n",
    "    lb_p[i] = np.sqrt(a+b)\n",
    "    ab[i,0], ab[i,1] = a,b\n",
    "    \n",
    "## Construction of the regularizers\n",
    "\n",
    "Gamdag = Gam.T@np.linalg.inv(Gam@Gam.T)\n",
    "Del = np.zeros((n,m,m))\n",
    "for j in range(m):\n",
    "    aj = ab[j,0]\n",
    "    bj = ab[j,1]\n",
    "    Rj = R_aug[:,:,j]\n",
    "    Qj = Q_aug[:,:,j]\n",
    "    aux = Gamdag - U@np.linalg.inv(U.T@(aj*Rj.T@Rj+bj*S.T@S)@U)@U.T@(aj*Rj.T@Rj+bj*S.T@S)@Gamdag\n",
    "    Del[:,:,j] = Qj@aux   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Worst-case errors for several linear recovery maps\n",
    "\n",
    "The computation below is based on Proposition 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computed lower bound on the global worst-case error is 2.4198.\n",
      "\n",
      "The global worst-case error of an optimal linear recovery map is 8.8989.\n",
      "\n",
      "The upper bound on the global worst-case error using the earlier regularization map 17.1312.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for the linear map given by regularization\n",
    "k = np.argmax(lb_p)\n",
    "a = cp.Variable((m,1), nonneg=True)\n",
    "b = cp.Variable((m,1), nonneg=True)\n",
    "gam = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(gam)\n",
    "constraints = [a[i]+b[i]<=gam for i in range(m)]\n",
    "for i in range(m):\n",
    "    aux = Q_aug[:,:,i] - Del[:,:,k]@Gam\n",
    "    Ri = R_aug[:,:,i]\n",
    "    Mi1 = cp.hstack( (np.identity(n), aux) ) \n",
    "    Mi2 = cp.hstack( (aux.T, cp.multiply(a[i],Ri.T@Ri) + cp.multiply(b[i],S.T@S)) )\n",
    "    constraints += [cp.vstack((Mi1,Mi2))>>0]\n",
    "sdp1 = cp.Problem(objective,constraints)\n",
    "sdp1.solve()\n",
    "ub = np.sqrt(gam.value[0,0])\n",
    "\n",
    "# for a linear recovery map treated as a variable in the SDP\n",
    "a = cp.Variable((m,1), nonneg=True)\n",
    "b = cp.Variable((m,1), nonneg=True)\n",
    "Del_lin = cp.Variable((n,m))\n",
    "gam = cp.Variable((1,1), nonneg=True)\n",
    "objective = cp.Minimize(gam)\n",
    "constraints = [a[i]+b[i]<=gam for i in range(m)]\n",
    "for i in range(m):\n",
    "    aux = Q_aug[:,:,i] - Del_lin@Gam\n",
    "    Ri = R_aug[:,:,i]\n",
    "    Mi1 = cp.hstack( (np.identity(n), aux) ) \n",
    "    Mi2 = cp.hstack( (aux.T, cp.multiply(a[i],Ri.T@Ri) + cp.multiply(b[i],S.T@S)) )\n",
    "    constraints += [cp.vstack((Mi1,Mi2))>>0]\n",
    "sdp1 = cp.Problem(objective,constraints)\n",
    "sdp1.solve()\n",
    "gam = np.sqrt(gam.value[0,0])\n",
    "\n",
    "print(f'The computed lower bound on the global worst-case error is {np.max(lb_p):.4f}.\\n',)\n",
    "print(f'The global worst-case error of an optimal linear recovery map is {gam:.4f}.\\n')\n",
    "print(f'The upper bound on the global worst-case error using the earlier regularization map {ub:.4f}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "[1] S. Foucart and C. Liao, \"Radius of Information for Two Intersected Centered Hyperellipsoids and Implications in Optimal Recovery from Inaccurate Data\", Preprint.\n",
    "\n",
    "[2] S. Diamond and S. Boyd, \"CVXPY: A Python-embedded modeling language for convex optimization\", Journal of Machine Learning Research, 17(83):1–5, 2016.\n",
    "\n",
    "[3] S. Foucart and C. Liao, \"Optimal recovery from inaccurate data in Hilbert spaces: regularize, but what of the parameter?\", Constructive Approximation, pages 1–32, 2022. \n",
    "\n",
    "[4] S. Foucart, C. Liao and N. Veldt. \"On the optimal recovery of graph signals\". In 2023 International Conference on Sampling Theory and Applications (SampTA), pages 1–5, 2023. doi: 10.1109/ SampTA59647.2023.10301205. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
